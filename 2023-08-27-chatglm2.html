<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=1"><meta name="renderer" content="webkit"><title>ChatGLM2-6B-int4 模型初步尝试 | BLOG | HDSKY</title><meta name="format-detection" content="telephone=no"><meta name="description" content="是一款国内推出的开源的自然语言模型，通过 chatglm2-6b-int4 模型能够在6G左右的显卡以及CPU下实现调用，比较适合个人电脑部署。"><meta name="keywords" content="黑&amp;蛋,个人博客,Linux,Ubuntu,Centos,HPC,tag.name,tag.name"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="applicable-device" content="pc,mobile"><link href="/dist/iris-20b518ec25.css" rel="stylesheet"><script src="https://cdn.jsdelivr.net/npm/instant.page@3.0.0/instantpage.min.js" type="module" defer></script><script>var TinyCache=function(){"use strict";var n=window.localStorage,t=document;function e(n){return new Error("Failed to load "+n.name+": "+n.url)}function r(n){return new Error("No such item or item is staled: "+n.name)}function o(n,e){var r=t.createElement("script");r.id=n.name,r.text=e,r.defer=!0,t.getElementsByTagName("head")[0].appendChild(r)}function i(n,r){var o=t.createElement("script");o.id=n.name,o.src=n.url,o.onload=function(){r(null)},o.onerror=function(){r(e(n))},t.getElementsByTagName("body")[0].appendChild(o)}function u(t,e,r){!function(t,e){try{n.setItem(t,JSON.stringify(e))}catch(t){}}(""+t+e.name,{content:r,expire:e.maxAge?(new Date).getTime()+1e3*e.maxAge:null,name:e.name,url:e.url})}return function(){function t(n){this.config={prefix:"TC:",timeout:6e3},function(n,t){for(var e in t)t.hasOwnProperty(e)&&(n[e]=t[e])}(this.config,n)}var a=t.prototype;return a.load=function(n,t){var e,r,o,i,u=this;if(!t)return new Promise((function(t,e){u.load(n,(function(n){n?e(n):t()}))}));e=n.map((function(n){return function(t){u.loadScript(n,t)}})),r=t,o=[],i=e.length,e.forEach((function(n,t){n((function(n,e){o[t]=e,n&&r&&(r(n),r=null),0==--i&&r&&r(null,o)}))}))},a.remove=function(n){!function(n){try{localStorage.removeItem(n)}catch(n){}}(""+this.config.prefix+n.name)},a.loadScript=function(t,a){var c=this;!function(t,e,o){var i=function(t){var e,r=null;try{var o=n.getItem(t);o&&(r=JSON.parse(o))&&("string"!=typeof(e=r).name||"string"!=typeof e.url||"string"!=typeof e.content)&&(r=null)}catch(t){}return r}(""+t+e.name);i?i.url!==e.url||i.expire&&i.expire<(new Date).getTime()?o(r(e)):o(null,i.content):o(r(e))}(this.config.prefix,t,(function(n,r){var l,f,m,s;n?(l=t,f=c.config.timeout,m=function(n,e){e&&!n?(o(t,e),u(c.config.prefix,t,e),a(null)):i(t,a)},(s=new XMLHttpRequest).open("GET",l.url,!0),s.timeout=f,s.onload=function(){200<=s.status&&s.status<300||304===s.status?m(null,s.responseText):m(e(l))},s.ontimeout=s.onerror=function(){m(e(l))},s.send()):r?(o(t,r),a(null)):i(t,a)}))},t}()}()</script><script>(new TinyCache).load([{url:"/dist/iris-dfae13bc3a.js",name:"iris"}])</script><meta http-equiv="x-dns-prefetch-control" content="on"><link rel="dns-prefetch" href="//www.googletagmanager.com"><link rel="dns-prefetch" href="//hdsky-pw.disqus.com"><link rel="shortcut icon" type="image/ico" href="/favicon.ico"><link rel="icon" type="image/png" href="/favicon-192x192.png"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><meta property="og:title" content="ChatGLM2-6B-int4 模型初步尝试 | BLOG | HDSKY"><meta property="og:type" content="blog"><meta property="og:url" content="https://hdsky.pw/2023-08-27-chatglm2.html"><meta property="og:image" content="/favicon-192x192.png"><meta property="og:description" content="是一款国内推出的开源的自然语言模型，通过 chatglm2-6b-int4 模型能够在6G左右的显卡以及CPU下实现调用，比较适合个人电脑部署。"><meta property="og:article:tag" content="黑&amp;蛋,个人博客,Linux,Ubuntu,Centos,HPC,tag.name,tag.name"><meta property="og:locale" content="zh-Hans"><meta property="article:published_time" content="Sun Aug 27 2023 05:11:12 GMT+0800"><meta property="article:modified_time" content="Sun Aug 27 2023 23:15:15 GMT+0800"><meta name="twitter:card" content="summary"><script async src="https://www.googletagmanager.com/gtag/js?id=G-BNEM1LH28R"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-BNEM1LH28R")</script><script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://hdsky.pw"
    },
    "headline": "ChatGLM2-6B-int4 模型初步尝试",
    
    "datePublished": "2023-08-26T21:11:12.000Z",
    "dateModified": "2023-08-27T15:15:15.051Z",
    "author": {
        "@type": "Person",
        "name": "黑&amp;蛋",
        "image": {
            "@type": "ImageObject",
            "url": "avatar.png"
        },
        "description": "黑&amp;蛋的个人博客"
    },
    "publisher": {
        "@type": "Organization",
        "name": "BLOG | HDSKY",
        "logo": {
            "@type": "ImageObject",
            "url": "/favicon-192x192.png"
        }
    },
    "keywords": "黑&amp;蛋,个人博客,Linux,Ubuntu,Centos,HPC,tag.name,tag.name",
    "description": "是一款国内推出的开源的自然语言模型，通过 chatglm2-6b-int4 模型能够在6G左右的显卡以及CPU下实现调用，比较适合个人电脑部署。"
}</script><script>"serviceWorker"in navigator&&navigator.serviceWorker.getRegistrations().then((function(e){e.map((function(e){e.unregister()}))}))</script><meta name="generator" content="Hexo 6.3.0"></head><body data-instant-intensity="viewport"><header class="header header__no-hero"><div class="header-wrapper"><div class="header__left"><div class="header-logo"><a href="/">BLOG | HDSKY</a></div></div><div class="header__right"><nav class="nav"><a id="nav-toggle" class="nav-toggle"><div></div></a><div class="nav-wrapper"><ul><li><a class="nav-link" href="/links">Link</a></li><li><a class="nav-link" href="/archives">Archive</a></li><li><a class="nav-link" href="/about">About</a></li></ul></div></nav></div></div></header><main class="main"><article class="post"><header class="post-header"><h1 class="post-title">ChatGLM2-6B-int4 模型初步尝试</h1><section class="post-meta"><time datetime="2023-08-26T21:11:12.000Z"><i class="far fa-calendar" aria-hidden></i> 2023-08-27</time></section></header><aside class="post-aside"><section class="post-toc"><header class="post-toc-title">Contents</header><ol class="post-toc-inst"><li class="post-toc-inst-item post-toc-inst-level-2"><a class="post-toc-inst-link" href="#%E4%BB%8B%E7%BB%8D"><span class="post-toc-inst-number">1.</span> <span class="post-toc-inst-text">介绍</span></a></li><li class="post-toc-inst-item post-toc-inst-level-2"><a class="post-toc-inst-link" href="#%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87-%EF%BC%88Base-on-Ubuntu%EF%BC%89"><span class="post-toc-inst-number">2.</span> <span class="post-toc-inst-text">前期准备 （Base on Ubuntu）</span></a><ol class="post-toc-inst-child"><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E5%AE%89%E8%A3%85git-lfs"><span class="post-toc-inst-number">2.1.</span> <span class="post-toc-inst-text">安装git-lfs</span></a></li><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E5%87%86%E5%A4%87%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-optional"><span class="post-toc-inst-number">2.2.</span> <span class="post-toc-inst-text">准备模型文件 (optional)</span></a></li><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E5%87%86%E5%A4%87%E9%A1%B9%E7%9B%AE%E6%96%87%E4%BB%B6"><span class="post-toc-inst-number">2.3.</span> <span class="post-toc-inst-text">准备项目文件</span></a></li></ol></li><li class="post-toc-inst-item post-toc-inst-level-2"><a class="post-toc-inst-link" href="#Just-do-it"><span class="post-toc-inst-number">3.</span> <span class="post-toc-inst-text">Just do it</span></a><ol class="post-toc-inst-child"><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E5%88%9B%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83-optional"><span class="post-toc-inst-number">3.1.</span> <span class="post-toc-inst-text">创建虚拟环境 (optional)</span></a></li><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E8%BF%9B%E5%85%A5%E5%88%B0%E9%A1%B9%E7%9B%AE%E6%96%87%E4%BB%B6%E5%A4%B9%EF%BC%8C%E5%AE%89%E8%A3%85%E4%BE%9D%E8%B5%96%E7%8E%AF%E5%A2%83"><span class="post-toc-inst-number">3.2.</span> <span class="post-toc-inst-text">进入到项目文件夹，安装依赖环境</span></a></li><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E4%BF%AE%E6%94%B9-cli-demo-py-%E4%B8%AD%E7%9A%84%E5%86%85%E5%AE%B9%EF%BC%8C%E6%8C%87%E5%AE%9A%E6%88%90%E6%88%91%E4%BB%AC%E5%B7%B2%E7%BB%8F%E4%B8%8B%E8%BD%BD%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E6%96%87%E4%BB%B6-optional"><span class="post-toc-inst-number">3.3.</span> <span class="post-toc-inst-text">修改 cli_demo.py 中的内容，指定成我们已经下载好的模型文件 (optional)</span></a></li><li class="post-toc-inst-item post-toc-inst-level-3"><a class="post-toc-inst-link" href="#%E7%84%B6%E5%90%8E%E7%9B%B4%E6%8E%A5%E6%89%A7%E8%A1%8C"><span class="post-toc-inst-number">3.4.</span> <span class="post-toc-inst-text">然后直接执行</span></a></li></ol></li></ol></section></aside><section class="post-content"><p>是一款国内推出的开源的自然语言模型，通过 <code>chatglm2-6b-int4</code> 模型能够在6G左右的显卡以及CPU下实现调用，比较适合个人电脑部署。<span id="more"></span></p><p>项目地址 <a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM2-6B">https://github.com/THUDM/ChatGLM2-6B</a></p><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>ChatGLM<strong>2</strong>-6B 是开源中英双语对话模型 <a target="_blank" rel="noopener" href="https://github.com/THUDM/ChatGLM-6B">ChatGLM-6B</a> 的第二代版本，在保留了初代模型对话流畅、部署门槛较低等众多优秀特性的基础之上，ChatGLM<strong>2</strong>-6B 引入了如下新特性：</p><ol><li><strong>更强大的性能</strong>：基于 ChatGLM 初代模型的开发经验，我们全面升级了 ChatGLM2-6B 的基座模型。ChatGLM2-6B 使用了 <a target="_blank" rel="noopener" href="https://github.com/THUDM/GLM">GLM</a> 的混合目标函数，经过了 1.4T 中英标识符的预训练与人类偏好对齐训练，<a href="#%E8%AF%84%E6%B5%8B%E7%BB%93%E6%9E%9C">评测结果</a>显示，相比于初代模型，ChatGLM2-6B 在 MMLU（+23%）、CEval（+33%）、GSM8K（+571%） 、BBH（+60%）等数据集上的性能取得了大幅度的提升，在同尺寸开源模型中具有较强的竞争力。</li><li><strong>更长的上下文</strong>：基于 <a target="_blank" rel="noopener" href="https://github.com/HazyResearch/flash-attention">FlashAttention</a> 技术，我们将基座模型的上下文长度（Context Length）由 ChatGLM-6B 的 2K 扩展到了 32K，并在对话阶段使用 8K 的上下文长度训练。对于更长的上下文，我们发布了 <a target="_blank" rel="noopener" href="https://huggingface.co/THUDM/chatglm2-6b-32k">ChatGLM2-6B-32K</a> 模型。<a target="_blank" rel="noopener" href="https://github.com/THUDM/LongBench">LongBench</a> 的测评结果表明，在等量级的开源模型中，ChatGLM2-6B-32K 有着较为明显的竞争优势。</li><li><strong>更高效的推理</strong>：基于 <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1911.02150">Multi-Query Attention</a> 技术，ChatGLM2-6B 有更高效的推理速度和更低的显存占用：在官方的模型实现下，推理速度相比初代提升了 42%，INT4 量化下，6G 显存支持的对话长度由 1K 提升到了 8K。</li><li><strong>更开放的协议</strong>：ChatGLM2-6B 权重对学术研究<strong>完全开放</strong>，在填写<a target="_blank" rel="noopener" href="https://open.bigmodel.cn/mla/form">问卷</a>进行登记后<strong>亦允许免费商业使用</strong>。</li></ol><h2 id="前期准备-（Base-on-Ubuntu）"><a href="#前期准备-（Base-on-Ubuntu）" class="headerlink" title="前期准备 （Base on Ubuntu）"></a>前期准备 （Base on Ubuntu）</h2><ul><li>安装好 CUDA 环境的 Ubuntu</li><li>Git &amp; git-lfs</li><li>Anaconda or Mambaforge (optional)</li></ul><h3 id="安装git-lfs"><a href="#安装git-lfs" class="headerlink" title="安装git-lfs"></a>安装git-lfs</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install git-lfs</span><br><span class="line">git lfs install</span><br></pre></td></tr></table></figure><p>参考：<a target="_blank" rel="noopener" href="https://github.com/git-lfs/git-lfs/wiki/Installation">https://github.com/git-lfs/git-lfs/wiki/Installation</a></p><h3 id="准备模型文件-optional"><a href="#准备模型文件-optional" class="headerlink" title="准备模型文件 (optional)"></a>准备模型文件 (optional)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://huggingface.co/THUDM/chatglm2-6b-int4</span><br></pre></td></tr></table></figure><h3 id="准备项目文件"><a href="#准备项目文件" class="headerlink" title="准备项目文件"></a>准备项目文件</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/THUDM/ChatGLM2-6B.git</span><br></pre></td></tr></table></figure><h2 id="Just-do-it"><a href="#Just-do-it" class="headerlink" title="Just do it"></a>Just do it</h2><p>通过上面的准备工作，我们获得了两个文件夹 <code>chatglm2-6b-int4</code> 和 <code>ChatGLM2-6B</code>，分别是存放的项目文件和模型文件。</p><h3 id="创建虚拟环境-optional"><a href="#创建虚拟环境-optional" class="headerlink" title="创建虚拟环境 (optional)"></a>创建虚拟环境 (optional)</h3><p>创建一个虚拟环境，我们将其命名为 chatglm2，进入其中并安装好 python 和 pip</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda create -n chatglm2</span><br><span class="line">conda activate chatglm2</span><br><span class="line">conda install python</span><br></pre></td></tr></table></figure><h3 id="进入到项目文件夹，安装依赖环境"><a href="#进入到项目文件夹，安装依赖环境" class="headerlink" title="进入到项目文件夹，安装依赖环境"></a>进入到项目文件夹，安装依赖环境</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd ChatGLM2-6B</span><br><span class="line">pip install -r requirements.txt -i https://mirror.sjtu.edu.cn/pypi/web/simple</span><br></pre></td></tr></table></figure><h3 id="修改-cli-demo-py-中的内容，指定成我们已经下载好的模型文件-optional"><a href="#修改-cli-demo-py-中的内容，指定成我们已经下载好的模型文件-optional" class="headerlink" title="修改 cli_demo.py 中的内容，指定成我们已经下载好的模型文件 (optional)"></a>修改 <code>cli_demo.py</code> 中的内容，指定成我们已经下载好的模型文件 (optional)</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model = AutoModel.from_pretrained(&quot;/home/hdsky/chatglm2/chatglm2-6b-int4&quot;, trust_remote_code=True).cuda()</span><br></pre></td></tr></table></figure><h3 id="然后直接执行"><a href="#然后直接执行" class="headerlink" title="然后直接执行"></a>然后直接执行</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python cli_demo.py</span><br></pre></td></tr></table></figure></section><footer class="post-meta"><section class="tags"><a href="/tags/Linux/"><i class="fas fa-tag" aria-hidden></i> Linux </a><a href="/tags/Chatglm2/"><i class="fas fa-tag" aria-hidden></i> Chatglm2</a></section></footer><div class="post-end" data-text="End"></div></article><section><div id="disqus_thread"></div><script>!function(s){window.DISQUS=null;var e=s.createElement("link");e.rel="stylesheet",e.href="https://cdn.jsdelivr.net/npm/disqusjs@1.2.3/dist/disqusjs.css",s.head.appendChild(e);var t=s.createElement("script");t.async=!0,t.src="https://cdn.jsdelivr.net/npm/disqusjs@1.2.3/dist/disqus.js",t.onload=function(){new DisqusJS({shortname:"hdsky-pw",siteName:"BLOG | HDSKY",identifier:"2023-08-27-chatglm2",url:"https://hdsky.pw/2023-08-27-chatglm2.html",title:"ChatGLM2-6B-int4 模型初步尝试",api:"",apikey:"nvPDNH7YoE53bGKClf2CTyHqz9pYcnEsDoMFdpBEdarIrYJNfsdSDrAioHU5292n",admin:"disqus_trck5pCCAM",adminLabel:""})},s.head.appendChild(t)}(document)</script></section></main><footer class="footer"><div class="footer-wrapper"><p class="copyright">&copy; 2016 - 2023 黑&amp;蛋</p><p class="theme">Hexo Theme <a href="https://github.com/giuem/hexo-theme-iris" target="_blank" rel="noopener noreferrer">Iris</a> with <i class="fas fa-heart"></i></p></div></footer></body></html>